{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybacktestchain in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (0.4.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.23.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (2.2.2)\n",
      "Requirement already satisfied: scipy<1.14.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (1.13.1)\n",
      "Requirement already satisfied: sec-cik-mapper<3.0.0,>=2.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (2.1.0)\n",
      "Requirement already satisfied: yfinance<0.3.0,>=0.2.41 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pybacktestchain) (0.2.44)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.2.2->pybacktestchain) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.2.2->pybacktestchain) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=2.2.2->pybacktestchain) (2023.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (2.32.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (4.11.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (3.10.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yfinance<0.3.0,>=0.2.41->pybacktestchain) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance<0.3.0,>=0.2.41->pybacktestchain) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance<0.3.0,>=0.2.41->pybacktestchain) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\asus\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance<0.3.0,>=0.2.41->pybacktestchain) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->sec-cik-mapper<3.0.0,>=2.1.0->pybacktestchain) (2024.8.30)\n",
      "Requirement already satisfied: web3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (7.6.1)\n",
      "Requirement already satisfied: eth-abi>=5.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (5.1.0)\n",
      "Requirement already satisfied: eth-account>=0.13.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (0.13.4)\n",
      "Requirement already satisfied: eth-hash>=0.5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-hash[pycryptodome]>=0.5.1->web3) (0.7.0)\n",
      "Requirement already satisfied: eth-typing>=5.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (5.0.1)\n",
      "Requirement already satisfied: eth-utils>=5.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (5.1.0)\n",
      "Requirement already satisfied: hexbytes>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (1.2.1)\n",
      "Requirement already satisfied: aiohttp>=3.7.4.post0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (3.9.5)\n",
      "Requirement already satisfied: pydantic>=2.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (2.5.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (2.32.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (4.11.0)\n",
      "Requirement already satisfied: types-requests>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (2.32.0.20241016)\n",
      "Requirement already satisfied: websockets<14.0.0,>=10.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (13.1)\n",
      "Requirement already satisfied: pyunormalize>=15.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (16.0.0)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (305.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp>=3.7.4.post0->web3) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp>=3.7.4.post0->web3) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp>=3.7.4.post0->web3) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp>=3.7.4.post0->web3) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp>=3.7.4.post0->web3) (1.9.3)\n",
      "Requirement already satisfied: parsimonious<0.11.0,>=0.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-abi>=5.0.1->web3) (0.10.0)\n",
      "Requirement already satisfied: bitarray>=2.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (3.0.0)\n",
      "Requirement already satisfied: eth-keyfile<0.9.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (0.8.1)\n",
      "Requirement already satisfied: eth-keys>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (0.6.0)\n",
      "Requirement already satisfied: eth-rlp>=2.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (2.1.0)\n",
      "Requirement already satisfied: rlp>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (4.0.1)\n",
      "Requirement already satisfied: ckzg>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-account>=0.13.1->web3) (2.0.1)\n",
      "Requirement already satisfied: pycryptodome<4,>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-hash[pycryptodome]>=0.5.1->web3) (3.21.0)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-utils>=5.0.0->web3) (0.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic>=2.4.0->web3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic>=2.4.0->web3) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.23.0->web3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.23.0->web3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.23.0->web3) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.23.0->web3) (2024.8.30)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cytoolz>=0.10.1->eth-utils>=5.0.0->web3) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.3.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from parsimonious<0.11.0,>=0.10.0->eth-abi>=5.0.1->web3) (2023.10.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pybacktestchain\n",
    "!pip install web3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Blockchain with name backtest already exists. Please use a different name.\n",
      "INFO:root:Running backtest from 2019-01-01 00:00:00 to 2020-01-01 00:00:00.\n",
      "INFO:root:Retrieving price data for universe\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-02 00:00:00\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11211: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  base_cov = np.cov(mat.T, ddof=ddof)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:Optimization did not converge\n",
      "INFO:root:Stop loss triggered for NVDA at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for NFLX at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for CSCO at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-01-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-02-28 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-03-06 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-03-29 00:00:00\n",
      "WARNING:root:Not enough cash to buy 8862 of TSLA on 2019-03-29 00:00:00. Needed: 164608.69874954224, Available: 164607.84814929962\n",
      "INFO:root:Buying as many shares of TSLA as possible with available cash.\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-04-26 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-04-30 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-05-18 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-05-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-06-28 00:00:00\n",
      "WARNING:root:Not enough cash to buy 13022 of NVDA on 2019-06-28 00:00:00. Needed: 52826.36280918121, Available: 52821.33052420616\n",
      "INFO:root:Buying as many shares of NVDA as possible with available cash.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-07-31 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-08-16 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-08-30 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-09-30 00:00:00\n",
      "WARNING:root:Not enough cash to buy 548 of TSLA on 2019-09-30 00:00:00. Needed: 8845.816108703613, Available: 8842.727783441544\n",
      "INFO:root:Buying as many shares of TSLA as possible with available cash.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-10-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-11-29 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-12-31 00:00:00\n",
      "WARNING:root:Not enough cash to buy 1720 of CSCO on 2019-12-31 00:00:00. Needed: 70044.16946411133, Available: 69950.47739243507\n",
      "INFO:root:Buying as many shares of CSCO as possible with available cash.\n",
      "INFO:root:Backtest completed. Final portfolio value: 1729534.740373373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Block 0\n",
      "--------------------------------------------------------------------------------\n",
      "Backtest: Genesis Block\n",
      "Timestamp: 1735640890.7700677\n",
      "Hash: 5e687161c257fea2c315496aee5091b8aacc76e9d560f933a574a6625b31a713\n",
      "Previous Hash: 0\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Block 1\n",
      "--------------------------------------------------------------------------------\n",
      "Backtest: AmberWolfBlacksmith\n",
      "Timestamp: 1735640902.6022513\n",
      "Hash: 238dd8c6591c8af3b5708ef655fb38853213ba7293fdd440e9a627fcef88d5d3\n",
      "Previous Hash: 5e687161c257fea2c315496aee5091b8aacc76e9d560f933a574a6625b31a713\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Block 2\n",
      "--------------------------------------------------------------------------------\n",
      "Backtest: VioletEagleAstronaut\n",
      "Timestamp: 1735643954.634067\n",
      "Hash: 871a9d55b4a09f6c827dc40cd014878a59b8ce641fba3ec0f390482688a0ab45\n",
      "Previous Hash: 238dd8c6591c8af3b5708ef655fb38853213ba7293fdd440e9a627fcef88d5d3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pybacktestchain.data_module import FirstTwoMoments\n",
    "from pybacktestchain.broker import Backtest, StopLoss\n",
    "from pybacktestchain.blockchain import load_blockchain\n",
    "from datetime import datetime\n",
    "\n",
    "# Set verbosity for logging\n",
    "verbose = False  # Set to True to enable logging, or False to suppress it\n",
    "\n",
    "backtest = Backtest(\n",
    "    initial_date=datetime(2019, 1, 1),\n",
    "    final_date=datetime(2020, 1, 1),\n",
    "    information_class=FirstTwoMoments,\n",
    "    risk_model=StopLoss,\n",
    "    name_blockchain='backtest',\n",
    "    verbose=verbose\n",
    ")\n",
    "\n",
    "backtest.run_backtest()\n",
    "\n",
    "block_chain = load_blockchain('backtest')\n",
    "print(str(block_chain))\n",
    "# check if the blockchain is valid\n",
    "print(block_chain.is_valid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a code that leverages pybacktestchain to run a backtest on a user-defined trading strategy, evaluating its profitability and innovativeness. \n",
    "It calculates key performance metrics like net profit, Sharpe ratio, and maximum drawdown, while comparing the strategy to historical ones using pattern correlation. \n",
    "Results are stored in a blockchain to ensure transparency and traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Block', 'Blockchain', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'dataclass', 'field', 'hashlib', 'load_blockchain', 'os', 'pickle', 'remove_blockchain', 'time']\n"
     ]
    }
   ],
   "source": [
    "import pybacktestchain.blockchain as blockchain\n",
    "print(dir(blockchain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Blockchain with name user_strategy_analysis already exists. Please use a different name.\n",
      "INFO:root:Running backtest from 2019-01-01 00:00:00 to 2020-01-01 00:00:00.\n",
      "INFO:root:Retrieving price data for universe\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-02 00:00:00\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11211: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  base_cov = np.cov(mat.T, ddof=ddof)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:Optimization did not converge\n",
      "INFO:root:Stop loss triggered for NVDA at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for NFLX at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for CSCO at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-01-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-02-28 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-03-06 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-03-29 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-04-26 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-04-30 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-05-18 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-05-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-06-28 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-07-31 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-08-16 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-08-30 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-09-30 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-10-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-11-29 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-12-31 00:00:00\n",
      "WARNING:root:Not enough cash to buy 2179 of CSCO on 2019-12-31 00:00:00. Needed: 88736.18910598755, Available: 88574.31705713272\n",
      "INFO:root:Buying as many shares of CSCO as possible with available cash.\n",
      "INFO:root:Backtest completed. Final portfolio value: 2191084.4415516853\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\1436809057.py:67: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Action Ticker  Quantity      Price          Cash\n",
      "0  2019-01-31    BUY   NVDA    290529   3.407105  10137.200000\n",
      "1  2019-01-31    BUY   TSLA       492  20.584667      9.544189\n",
      "2  2019-02-28   SELL   NVDA     12749   3.853979  49143.920000\n",
      "3  2019-02-28    BUY   TSLA      2342  20.982668      2.515596\n",
      "4  2019-03-06   SELL   TSLA      2834  18.436001  52250.140000\n",
      "Net Profit: 1354852705.144972\n",
      "Sharpe Ratio: 0.491131304237656\n",
      "{'Net Profit': 1354852705.144972, 'Sharpe Ratio': 0.491131304237656}\n",
      "Innovation Score: 1\n",
      "{'Innovation Score': 1}\n",
      "Blockchain saved to blockchain.pkl\n"
     ]
    }
   ],
   "source": [
    "from pybacktestchain.data_module import FirstTwoMoments\n",
    "from pybacktestchain.broker import Backtest, StopLoss\n",
    "from pybacktestchain.blockchain import load_blockchain\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Ensures that the user's strategy is correctly applied to the market data.\n",
    "def apply_user_strategy(strategy_function, data):\n",
    "    \"\"\"\n",
    "    Apply the user's strategy to the data.\n",
    "    :param strategy_function: User-defined strategy function.\n",
    "    :param data: Historical market data (DataFrame).\n",
    "    :return: DataFrame with added 'Signal' column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the strategy function can be applied\n",
    "        data = strategy_function(data)\n",
    "        if 'Signal' not in data.columns:\n",
    "            raise ValueError(\"The strategy function must add a 'Signal' column to the data.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying user strategy: {e}\")\n",
    "        raise\n",
    "\n",
    "# Initialize the backtest\n",
    "backtest = Backtest(\n",
    "    initial_date=datetime(2019, 1, 1),\n",
    "    final_date=datetime(2020, 1, 1),\n",
    "    information_class=FirstTwoMoments,\n",
    "    risk_model=StopLoss,\n",
    "    name_blockchain='user_strategy_analysis',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example of user-defined strategy (replace with user input)\n",
    "def user_defined_strategy(data):\n",
    "    \"\"\"\n",
    "    Example: Moving Average Crossover Strategy.\n",
    "    Users can replace this with their own strategy.\n",
    "    \"\"\"\n",
    "    short_ma = data['Close'].rolling(window=10).mean()\n",
    "    long_ma = data['Close'].rolling(window=50).mean()\n",
    "    data['Signal'] = np.where(short_ma > long_ma, 1, -1)  # 1: Buy, -1: Sell\n",
    "    return data\n",
    "\n",
    "# Apply the user's strategy to the backtest\n",
    "try:\n",
    "    backtest.strategy = lambda data: apply_user_strategy(user_defined_strategy, data)\n",
    "    backtest.run_backtest()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to run the backtest: {e}\")\n",
    "\n",
    "# Load the blockchain\n",
    "blockchain = load_blockchain('user_strategy_analysis')\n",
    "\n",
    "# Extract trades from a single block\n",
    "def extract_trades_from_block(block):\n",
    "    \"\"\"\n",
    "    Extract trades from a block's data field.\n",
    "    \"\"\"\n",
    "    if block.data:\n",
    "        try:\n",
    "            # Parse the data string into a DataFrame\n",
    "            df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing block data: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Extract all trades from the blockchain\n",
    "def extract_all_trades(blockchain):\n",
    "    \"\"\"\n",
    "    Extract trades from all blocks in the blockchain.\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    for block in blockchain.chain:\n",
    "        trades_df = extract_trades_from_block(block)\n",
    "        if trades_df is not None:\n",
    "            trades.append(trades_df)\n",
    "    # Combine all trade data into a single DataFrame\n",
    "    if trades:\n",
    "        return pd.concat(trades, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Analyze profitability\n",
    "def calculate_profitability(trades_df):\n",
    "    \"\"\"\n",
    "    Calculate net profit and other key performance metrics.\n",
    "    \"\"\"\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades found.\")\n",
    "        return {\"Net Profit\": 0, \"Sharpe Ratio\": 0}\n",
    "\n",
    "    # Calculate net profit\n",
    "    trades_df['Profit'] = trades_df['Quantity'] * trades_df['Price']\n",
    "    net_profit = trades_df['Profit'].sum()\n",
    "\n",
    "    # Example: Calculate Sharpe Ratio\n",
    "    sharpe_ratio = trades_df['Profit'].mean() / trades_df['Profit'].std() if trades_df['Profit'].std() > 0 else 0\n",
    "\n",
    "    print(f\"Net Profit: {net_profit}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio}\")\n",
    "    return {\"Net Profit\": net_profit, \"Sharpe Ratio\": sharpe_ratio}\n",
    "\n",
    "# Analyze innovation of the strategy\n",
    "def analyze_innovation(trades_df):\n",
    "    \"\"\"\n",
    "    Analyze the innovation of the user's strategy.\n",
    "    Compare the strategy's signals or trading patterns against historical strategies.\n",
    "    \"\"\"\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades found to analyze innovation.\")\n",
    "        return {\"Innovation Score\": 0}\n",
    "\n",
    "    # Example: Compare the user's trades to a dummy historical pattern\n",
    "    # (In a real-world scenario, you would load historical strategies from a database)\n",
    "    historical_signals = np.random.choice([-1, 1], size=len(trades_df))  # Dummy historical signals\n",
    "    user_signals = trades_df['Signal'] if 'Signal' in trades_df else []\n",
    "\n",
    "    # Calculate innovation as 1 - correlation with historical signals\n",
    "    correlation = np.corrcoef(user_signals, historical_signals)[0, 1] if len(user_signals) > 1 else 0\n",
    "    innovation_score = 1 - correlation\n",
    "\n",
    "    print(f\"Innovation Score: {innovation_score}\")\n",
    "    return {\"Innovation Score\": innovation_score}\n",
    "\n",
    "# Save blockchain to a file using pickle\n",
    "def save_blockchain(blockchain, filename='blockchain.pkl'):\n",
    "    \"\"\"Save the blockchain object to a file.\"\"\"\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(blockchain, file)\n",
    "    print(f\"Blockchain saved to {filename}\")\n",
    "\n",
    "# Extract and analyze trades\n",
    "trades_df = extract_all_trades(blockchain)\n",
    "print(trades_df.head())  # Display the first few trades\n",
    "\n",
    "# Calculate profitability metrics\n",
    "profitability_metrics = calculate_profitability(trades_df)\n",
    "print(profitability_metrics)\n",
    "\n",
    "# Analyze innovation\n",
    "innovation_metrics = analyze_innovation(trades_df)\n",
    "print(innovation_metrics)\n",
    "\n",
    "# Save the blockchain\n",
    "save_blockchain(blockchain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Blockchain with name user_strategy_analysis already exists. Please use a different name.\n",
      "INFO:root:Running backtest from 2019-01-01 00:00:00 to 2020-01-01 00:00:00.\n",
      "INFO:root:Retrieving price data for universe\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-01 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function create_historical_strategies.<locals>.strategy_buy at 0x000001DC1504DC60>, <function create_historical_strategies.<locals>.strategy_sell at 0x000001DC15E7ECA0>, <function create_historical_strategies.<locals>.strategy_random at 0x000001DC15E7CD60>, <function create_historical_strategies.<locals>.strategy_short_momentum at 0x000001DC15E7EB60>, <function create_historical_strategies.<locals>.strategy_long_momentum at 0x000001DC15E7DD00>, <function create_historical_strategies.<locals>.strategy_mean_reversion at 0x000001DC15E7F420>, <function create_historical_strategies.<locals>.strategy_moving_average at 0x000001DC15E7D940>, <function create_historical_strategies.<locals>.strategy_above_ma at 0x000001DC15E7E520>, <function create_historical_strategies.<locals>.strategy_volatility_breakout at 0x000001DC15E7CB80>, <function create_historical_strategies.<locals>.strategy_rsi at 0x000001DC15E7E700>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:not enough values to unpack (expected 2, got 0)\n",
      "WARNING:root:Price for NVDA not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for NFLX not available on 2019-01-02 00:00:00\n",
      "WARNING:root:Price for CSCO not available on 2019-01-02 00:00:00\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11211: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  base_cov = np.cov(mat.T, ddof=ddof)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "WARNING:root:Error computing portfolio, returning equal weight portfolio\n",
      "WARNING:root:Optimization did not converge\n",
      "INFO:root:Stop loss triggered for NVDA at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for NFLX at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:Stop loss triggered for CSCO at 2019-01-03 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-01-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-02-28 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-03-06 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-03-29 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-04-26 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-04-30 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-05-18 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-05-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-06-28 00:00:00\n",
      "WARNING:root:Not enough cash to buy 16176 of NVDA on 2019-06-28 00:00:00. Needed: 65621.19834136963, Available: 65611.26830077171\n",
      "INFO:root:Buying as many shares of NVDA as possible with available cash.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-07-31 00:00:00\n",
      "INFO:root:Stop loss triggered for TSLA at 2019-08-16 00:00:00. Selling all shares.\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-08-30 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-09-30 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-10-31 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-11-29 00:00:00\n",
      "INFO:root:-----------------------------------\n",
      "INFO:root:Rebalancing portfolio at 2019-12-31 00:00:00\n",
      "WARNING:root:Not enough cash to buy 2137 of CSCO on 2019-12-31 00:00:00. Needed: 87025.80822372437, Available: 86994.6743414402\n",
      "INFO:root:Buying as many shares of CSCO as possible with available cash.\n",
      "INFO:root:Backtest completed. Final portfolio value: 2148339.024483919\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_19268\\155360676.py:172: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Profit: 1143106718.414781\n",
      "Sharpe Ratio: 0.491270304765847\n",
      "{'Net Profit': 1143106718.414781, 'Sharpe Ratio': 0.491270304765847}\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Error applying historical strategy: 'Close'\n",
      "Innovation Score: 1\n",
      "{'Innovation Score': 1}\n",
      "Blockchain saved to blockchain.pkl\n"
     ]
    }
   ],
   "source": [
    "from pybacktestchain.data_module import FirstTwoMoments\n",
    "from pybacktestchain.broker import Backtest, StopLoss\n",
    "from pybacktestchain.blockchain import load_blockchain\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pickle\n",
    "\n",
    "# Ensures that the user's strategy is correctly applied to the market data.\n",
    "def apply_user_strategy(strategy_function, data):\n",
    "    try:\n",
    "        data = strategy_function(data)\n",
    "        if 'Signal' not in data.columns:\n",
    "            raise ValueError(\"The strategy function must add a 'Signal' column to the data.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying user strategy: {e}\")\n",
    "        raise\n",
    "\n",
    "# Define historical strategies\n",
    "def create_historical_strategies():\n",
    "    \"\"\"\n",
    "    Create a list of basic historical strategies.\n",
    "    Each strategy function operates on the market data and generates signals.\n",
    "    :return: List of strategy functions.\n",
    "    \"\"\"\n",
    "    strategies = []\n",
    "\n",
    "    # Strategy 1: Always buy\n",
    "    def strategy_buy(data):\n",
    "        data['Signal'] = 1  # Always buy\n",
    "        return data\n",
    "    strategies.append(strategy_buy)\n",
    "\n",
    "    # Strategy 2: Always sell\n",
    "    def strategy_sell(data):\n",
    "        data['Signal'] = -1  # Always sell\n",
    "        return data\n",
    "    strategies.append(strategy_sell)\n",
    "\n",
    "    # Strategy 3: Random signals\n",
    "    def strategy_random(data):\n",
    "        data['Signal'] = np.random.choice([-1, 1], size=len(data))\n",
    "        return data\n",
    "    strategies.append(strategy_random)\n",
    "\n",
    "    # Strategy 4: Short-term momentum\n",
    "    def strategy_short_momentum(data):\n",
    "        short_term_diff = data['Close'].diff()\n",
    "        data['Signal'] = np.where(short_term_diff > 0, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_short_momentum)\n",
    "\n",
    "    # Strategy 5: Long-term momentum\n",
    "    def strategy_long_momentum(data):\n",
    "        long_term_mean = data['Close'].rolling(window=20).mean().diff()\n",
    "        data['Signal'] = np.where(long_term_mean > 0, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_long_momentum)\n",
    "\n",
    "    # Strategy 6: Mean reversion\n",
    "    def strategy_mean_reversion(data):\n",
    "        rolling_mean = data['Close'].rolling(window=10).mean()\n",
    "        data['Signal'] = np.where(data['Close'] < rolling_mean, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_mean_reversion)\n",
    "\n",
    "    # Strategy 7: Moving average crossover\n",
    "    def strategy_moving_average(data):\n",
    "        short_ma = data['Close'].rolling(window=5).mean()\n",
    "        long_ma = data['Close'].rolling(window=15).mean()\n",
    "        data['Signal'] = np.where(short_ma > long_ma, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_moving_average)\n",
    "\n",
    "    # Strategy 8: Price above moving average\n",
    "    def strategy_above_ma(data):\n",
    "        rolling_mean = data['Close'].rolling(window=10).mean()\n",
    "        data['Signal'] = np.where(data['Close'] > rolling_mean, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_above_ma)\n",
    "\n",
    "    # Strategy 9: Volatility breakout\n",
    "    def strategy_volatility_breakout(data):\n",
    "        rolling_mean = data['Close'].rolling(window=10).mean()\n",
    "        rolling_std = data['Close'].rolling(window=10).std()\n",
    "        data['Signal'] = np.where(data['Close'] > rolling_mean + 2 * rolling_std, 1, -1)\n",
    "        return data\n",
    "    strategies.append(strategy_volatility_breakout)\n",
    "\n",
    "    # Strategy 10: RSI-based strategy\n",
    "    def strategy_rsi(data):\n",
    "        delta = data['Close'].diff()\n",
    "        gain = np.where(delta > 0, delta, 0)\n",
    "        loss = np.where(delta < 0, -delta, 0)\n",
    "        avg_gain = pd.Series(gain).rolling(window=14).mean()\n",
    "        avg_loss = pd.Series(loss).rolling(window=14).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        data['Signal'] = np.where(rsi < 30, 1, np.where(rsi > 70, -1, 0))\n",
    "        return data\n",
    "    strategies.append(strategy_rsi)\n",
    "\n",
    "    return strategies\n",
    "\n",
    "historical_strategies = create_historical_strategies()\n",
    "\n",
    "# Analyze innovation of the strategy\n",
    "def analyze_innovation(trades_df, historical_strategies):\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades found to analyze innovation.\")\n",
    "        return {\"Innovation Score\": 0}\n",
    "\n",
    "    user_signals = trades_df['Signal'] if 'Signal' in trades_df.columns else []\n",
    "\n",
    "    historical_signals_list = []\n",
    "    for strategy in historical_strategies:\n",
    "        try:\n",
    "            historical_data = trades_df.copy()\n",
    "            historical_data = strategy(historical_data)\n",
    "            if 'Signal' in historical_data.columns:\n",
    "                historical_signals_list.append(historical_data['Signal'].to_numpy())\n",
    "        except Exception as e:\n",
    "            print(f\"Error applying historical strategy: {e}\")\n",
    "\n",
    "    correlations = []\n",
    "    for historical_signals in historical_signals_list:\n",
    "        if len(user_signals) == len(historical_signals):\n",
    "            correlation = np.corrcoef(user_signals, historical_signals)[0, 1]\n",
    "            correlations.append(correlation)\n",
    "\n",
    "    avg_correlation = np.mean(correlations) if correlations else 0\n",
    "    innovation_score = 1 - avg_correlation\n",
    "\n",
    "    print(f\"Innovation Score: {innovation_score}\")\n",
    "    return {\"Innovation Score\": innovation_score}\n",
    "\n",
    "# Initialize the backtest\n",
    "backtest = Backtest(\n",
    "    initial_date=datetime(2019, 1, 1),\n",
    "    final_date=datetime(2020, 1, 1),\n",
    "    information_class=FirstTwoMoments,\n",
    "    risk_model=StopLoss,\n",
    "    name_blockchain='user_strategy_analysis',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Example of user-defined strategy\n",
    "def user_defined_strategy(data):\n",
    "    short_ma = data['Close'].rolling(window=10).mean()\n",
    "    long_ma = data['Close'].rolling(window=50).mean()\n",
    "    data['Signal'] = np.where(short_ma > long_ma, 1, -1)\n",
    "    return data\n",
    "\n",
    "try:\n",
    "    backtest.strategy = lambda data: apply_user_strategy(user_defined_strategy, data)\n",
    "    backtest.run_backtest()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to run the backtest: {e}\")\n",
    "\n",
    "blockchain = load_blockchain('user_strategy_analysis')\n",
    "\n",
    "# Extract trades and analyze innovation\n",
    "def extract_all_trades(blockchain):\n",
    "    trades = []\n",
    "    for block in blockchain.chain:\n",
    "        if block.data:\n",
    "            try:\n",
    "                trades_df = pd.read_csv(StringIO(block.data), delim_whitespace=True)\n",
    "                trades.append(trades_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing block data: {e}\")\n",
    "    return pd.concat(trades, ignore_index=True) if trades else pd.DataFrame()\n",
    "\n",
    "trades_df = extract_all_trades(blockchain)\n",
    "\n",
    "# Placeholder for calculate_profitability function\n",
    "def calculate_profitability(trades_df):\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades found.\")\n",
    "        return {\"Net Profit\": 0, \"Sharpe Ratio\": 0}\n",
    "\n",
    "    trades_df['Profit'] = trades_df['Quantity'] * trades_df['Price']\n",
    "    net_profit = trades_df['Profit'].sum()\n",
    "    sharpe_ratio = trades_df['Profit'].mean() / trades_df['Profit'].std() if trades_df['Profit'].std() > 0 else 0\n",
    "\n",
    "    print(f\"Net Profit: {net_profit}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio}\")\n",
    "    return {\"Net Profit\": net_profit, \"Sharpe Ratio\": sharpe_ratio}\n",
    "\n",
    "profitability_metrics = calculate_profitability(trades_df)\n",
    "print(profitability_metrics)\n",
    "\n",
    "innovation_metrics = analyze_innovation(trades_df, historical_strategies)\n",
    "print(innovation_metrics)\n",
    "\n",
    "# Save blockchain\n",
    "def save_blockchain(blockchain, filename='blockchain.pkl'):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(blockchain, file)\n",
    "    print(f\"Blockchain saved to {filename}\")\n",
    "\n",
    "save_blockchain(blockchain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eth-brownie\n",
      "  Downloading eth_brownie-1.20.6-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: web3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (7.6.1)\n",
      "Collecting aiohttp==3.9.3 (from eth-brownie)\n",
      "  Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting aiosignal==1.3.1 (from eth-brownie)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting asttokens==2.4.1 (from eth-brownie)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting attrs==23.2.0 (from eth-brownie)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting bitarray==2.9.2 (from eth-brownie)\n",
      "  Downloading bitarray-2.9.2-cp312-cp312-win_amd64.whl.metadata (35 kB)\n",
      "Collecting black==24.2.0 (from eth-brownie)\n",
      "  Downloading black-24.2.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting cbor2==5.6.2 (from eth-brownie)\n",
      "  Downloading cbor2-5.6.2-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting certifi==2024.2.2 (from eth-brownie)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer==3.3.2 (from eth-brownie)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: click==8.1.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (8.1.7)\n",
      "Collecting cytoolz==0.12.3 (from eth-brownie)\n",
      "  Downloading cytoolz-0.12.3-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting dataclassy==0.11.1 (from eth-brownie)\n",
      "  Downloading dataclassy-0.11.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting eip712==0.2.4 (from eth-brownie)\n",
      "  Downloading eip712-0.2.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting eth-abi==5.0.0 (from eth-brownie)\n",
      "  Downloading eth_abi-5.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting eth-account==0.10.0 (from eth-brownie)\n",
      "  Downloading eth_account-0.10.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting eth-event==1.2.5 (from eth-brownie)\n",
      "  Downloading eth_event-1.2.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting eth-hash==0.6.0 (from eth-hash[pycryptodome]==0.6.0->eth-brownie)\n",
      "  Downloading eth_hash-0.6.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting eth-keyfile==0.7.0 (from eth-brownie)\n",
      "  Downloading eth_keyfile-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting eth-keys==0.5.0 (from eth-brownie)\n",
      "  Downloading eth_keys-0.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting eth-rlp==1.0.1 (from eth-brownie)\n",
      "  Downloading eth_rlp-1.0.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting eth-typing==3.5.2 (from eth-brownie)\n",
      "  Downloading eth_typing-3.5.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting eth-utils==2.3.1 (from eth-brownie)\n",
      "  Downloading eth_utils-2.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting execnet==2.0.2 (from eth-brownie)\n",
      "  Downloading execnet-2.0.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting frozenlist==1.4.1 (from eth-brownie)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting hexbytes==0.3.1 (from eth-brownie)\n",
      "  Downloading hexbytes-0.3.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting hypothesis==6.27.3 (from eth-brownie)\n",
      "  Downloading hypothesis-6.27.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting idna==3.6 (from eth-brownie)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: importlib-metadata==7.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (7.0.1)\n",
      "Collecting iniconfig==2.0.0 (from eth-brownie)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema==4.21.1 (from eth-brownie)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting jsonschema-specifications==2023.12.1 (from eth-brownie)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: lazy-object-proxy==1.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (1.10.0)\n",
      "Collecting lru-dict==1.2.0 (from eth-brownie)\n",
      "  Downloading lru-dict-1.2.0.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting multidict==6.0.5 (from eth-brownie)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (1.0.0)\n",
      "Requirement already satisfied: packaging==23.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (23.2)\n",
      "Collecting parsimonious==0.9.0 (from eth-brownie)\n",
      "  Downloading parsimonious-0.9.0.tar.gz (48 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pathspec==0.12.1 (from eth-brownie)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting platformdirs==4.2.0 (from eth-brownie)\n",
      "  Downloading platformdirs-4.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pluggy==1.4.0 (from eth-brownie)\n",
      "  Downloading pluggy-1.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (3.0.43)\n",
      "Collecting protobuf==4.25.3 (from eth-brownie)\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting psutil==5.9.8 (from eth-brownie)\n",
      "  Downloading psutil-5.9.8-cp37-abi3-win_amd64.whl.metadata (22 kB)\n",
      "Collecting py==1.11.0 (from eth-brownie)\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting py-solc-ast==1.2.10 (from eth-brownie)\n",
      "  Downloading py_solc_ast-1.2.10-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting py-solc-x==1.1.1 (from eth-brownie)\n",
      "  Downloading py_solc_x-1.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting pycryptodome==3.20.0 (from eth-brownie)\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting pygments==2.17.2 (from eth-brownie)\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pygments-lexer-solidity==0.7.0 (from eth-brownie)\n",
      "  Downloading pygments-lexer-solidity-0.7.0.tar.gz (7.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytest==6.2.5 (from eth-brownie)\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pytest-forked==1.6.0 (from eth-brownie)\n",
      "  Downloading pytest_forked-1.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pytest-xdist==1.34.0 (from eth-brownie)\n",
      "  Downloading pytest_xdist-1.34.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting python-dotenv==0.16.0 (from eth-brownie)\n",
      "  Downloading python_dotenv-0.16.0-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pyunormalize==15.1.0 (from eth-brownie)\n",
      "  Downloading pyunormalize-15.1.0.tar.gz (515 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml==6.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (6.0.1)\n",
      "Collecting referencing==0.33.0 (from eth-brownie)\n",
      "  Downloading referencing-0.33.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting regex==2023.12.25 (from eth-brownie)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests==2.31.0 (from eth-brownie)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rlp==4.0.0 (from eth-brownie)\n",
      "  Downloading rlp-4.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting rpds-py==0.18.0 (from eth-brownie)\n",
      "  Downloading rpds_py-0.18.0-cp312-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version==2.10.0 (from eth-brownie)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (1.16.0)\n",
      "Requirement already satisfied: sortedcontainers==2.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (2.4.0)\n",
      "Requirement already satisfied: toml==0.10.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (0.10.2)\n",
      "Collecting toolz==0.12.1 (from eth-brownie)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm==4.66.2 (from eth-brownie)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions==4.9.0 (from eth-brownie)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting urllib3==2.2.1 (from eth-brownie)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting vvm==0.1.0 (from eth-brownie)\n",
      "  Downloading vvm-0.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting vyper==0.3.10 (from eth-brownie)\n",
      "  Downloading vyper-0.3.10-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting wcwidth==0.2.13 (from eth-brownie)\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting web3\n",
      "  Downloading web3-6.15.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting websockets==12.0 (from eth-brownie)\n",
      "  Downloading websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting wheel==0.42.0 (from eth-brownie)\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting wrapt==1.16.0 (from eth-brownie)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting yarl==1.9.4 (from eth-brownie)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: zipp==3.17.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from eth-brownie) (3.17.0)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from web3) (305.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click==8.1.7->eth-brownie) (0.4.6)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pytest==6.2.5->eth-brownie) (1.4.0)\n",
      "Downloading eth_brownie-1.20.6-py3-none-any.whl (219 kB)\n",
      "Downloading web3-6.15.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading bitarray-2.9.2-cp312-cp312-win_amd64.whl (126 kB)\n",
      "Downloading black-24.2.0-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading cbor2-5.6.2-cp312-cp312-win_amd64.whl (66 kB)\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading cytoolz-0.12.3-cp312-cp312-win_amd64.whl (363 kB)\n",
      "Downloading dataclassy-0.11.1-py3-none-any.whl (23 kB)\n",
      "Downloading eip712-0.2.4-py3-none-any.whl (10 kB)\n",
      "Downloading eth_abi-5.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading eth_account-0.10.0-py3-none-any.whl (109 kB)\n",
      "Downloading eth_event-1.2.5-py3-none-any.whl (7.5 kB)\n",
      "Downloading eth_hash-0.6.0-py3-none-any.whl (8.6 kB)\n",
      "Downloading eth_keyfile-0.7.0-py3-none-any.whl (7.4 kB)\n",
      "Downloading eth_keys-0.5.0-py3-none-any.whl (21 kB)\n",
      "Downloading eth_rlp-1.0.1-py3-none-any.whl (4.9 kB)\n",
      "Downloading eth_typing-3.5.2-py3-none-any.whl (14 kB)\n",
      "Downloading eth_utils-2.3.1-py3-none-any.whl (77 kB)\n",
      "Downloading execnet-2.0.2-py3-none-any.whl (37 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Downloading hexbytes-0.3.1-py3-none-any.whl (5.9 kB)\n",
      "Downloading hypothesis-6.27.3-py3-none-any.whl (384 kB)\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading platformdirs-4.2.0-py3-none-any.whl (17 kB)\n",
      "Downloading pluggy-1.4.0-py3-none-any.whl (20 kB)\n",
      "Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading psutil-5.9.8-cp37-abi3-win_amd64.whl (255 kB)\n",
      "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Downloading py_solc_ast-1.2.10-py3-none-any.whl (10.0 kB)\n",
      "Downloading py_solc_x-1.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 16.1 MB/s eta 0:00:00\n",
      "Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
      "Downloading pytest_forked-1.6.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading pytest_xdist-1.34.0-py2.py3-none-any.whl (36 kB)\n",
      "Downloading python_dotenv-0.16.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.33.0-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl (268 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading rlp-4.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading rpds_py-0.18.0-cp312-none-win_amd64.whl (206 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading vvm-0.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading vyper-0.3.10-py3-none-any.whl (262 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n",
      "Downloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Building wheels for collected packages: lru-dict, parsimonious, pygments-lexer-solidity, pyunormalize\n",
      "  Building wheel for lru-dict (setup.py): started\n",
      "  Building wheel for lru-dict (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for lru-dict\n",
      "  Building wheel for parsimonious (setup.py): started\n",
      "  Building wheel for parsimonious (setup.py): finished with status 'done'\n",
      "  Created wheel for parsimonious: filename=parsimonious-0.9.0-py3-none-any.whl size=44379 sha256=8e05bbae4b27711dee2d832b40c27e1eceee478b4fafef691a11b46d9d07043e\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\83\\de\\47\\e7f4d777272d7044e17868c7804f488944016ae93455053b14\n",
      "  Building wheel for pygments-lexer-solidity (setup.py): started\n",
      "  Building wheel for pygments-lexer-solidity (setup.py): finished with status 'done'\n",
      "  Created wheel for pygments-lexer-solidity: filename=pygments_lexer_solidity-0.7.0-py3-none-any.whl size=7315 sha256=ac05662ae0a501165e504f5d63c6ac135a62838dec6a262e6c1d6ec0581593cf\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\a5\\48\\34\\103310eb32af3a9d91fd4920601aabeb13ae612e52beb8c954\n",
      "  Building wheel for pyunormalize (setup.py): started\n",
      "  Building wheel for pyunormalize (setup.py): finished with status 'done'\n",
      "  Created wheel for pyunormalize: filename=pyunormalize-15.1.0-py3-none-any.whl size=516050 sha256=76240a9b9cfbe880b28e6bd11e3776760c32ca3990daed69dc129e842f7c4373\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\2a\\bd\\bb\\28798325f033d03157374640b90b54298b4145d04209618850\n",
      "Successfully built parsimonious pygments-lexer-solidity pyunormalize\n",
      "Failed to build lru-dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   python setup.py bdist_wheel did not run successfully.\n",
      "   exit code: 1\n",
      "  > [5 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      building 'lru' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for lru-dict\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (lru-dict)\n",
      "'brownie' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme excutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!pip install eth-brownie web3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'brownie' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme excutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!brownie init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Block:\n",
    "    data: str\n",
    "    previous_hash: str = ''\n",
    "    timestamp: float = field(default_factory=time.time)\n",
    "    hash: str = field(init=False)\n",
    "    rewards: int = 0  # Reward for the block\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.hash = self.calculate_hash\n",
    "\n",
    "    @property\n",
    "    def calculate_hash(self):\n",
    "        return hashlib.sha256(\n",
    "            (str(self.timestamp) + self.data + self.previous_hash).encode()\n",
    "        ).hexdigest()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Blockchain:\n",
    "    chain: list = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.chain.append(self.create_genesis_block())\n",
    "\n",
    "    def create_genesis_block(self):\n",
    "        return Block('Genesis Block', '0')\n",
    "\n",
    "    def add_block(self, data: str, rewards: int):\n",
    "        previous_block = self.chain[-1]\n",
    "        new_block = Block(data, previous_block.hash, rewards=rewards)\n",
    "        self.chain.append(new_block)\n",
    "\n",
    "    def is_chain_valid(self):\n",
    "        for i in range(1, len(self.chain)):\n",
    "            current_block = self.chain[i]\n",
    "            previous_block = self.chain[i - 1]\n",
    "            if current_block.previous_hash != previous_block.hash:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (72485702.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pragma solidity ^0.8.0;\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract RewardToken {\n",
    "    string public name = \"Reward Token\";\n",
    "    string public symbol = \"RWD\";\n",
    "    uint8 public decimals = 18;\n",
    "    uint256 public totalSupply;\n",
    "\n",
    "    mapping(address => uint256) public balanceOf;\n",
    "\n",
    "    event Transfer(address indexed from, address indexed to, uint256 value);\n",
    "\n",
    "    constructor(uint256 initialSupply) {\n",
    "        totalSupply = initialSupply * 10 ** uint256(decimals);\n",
    "        balanceOf[msg.sender] = totalSupply; // Assign all tokens to the creator\n",
    "    }\n",
    "\n",
    "    function transfer(address to, uint256 value) public returns (bool success) {\n",
    "        require(balanceOf[msg.sender] >= value, \"Insufficient balance\");\n",
    "        balanceOf[msg.sender] -= value;\n",
    "        balanceOf[to] += value;\n",
    "        emit Transfer(msg.sender, to, value);\n",
    "        return true;\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
